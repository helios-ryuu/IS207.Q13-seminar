# SEO Analyzer - Backend API

Backend service cho SEO Analyzer Tool - ph√¢n t√≠ch SEO v√† AI Search optimization s·ª≠ d·ª•ng Puppeteer crawler v√† Cheerio parser.

## üöÄ C√¥ng ngh·ªá s·ª≠ d·ª•ng

- **Express.js 5.1.0** - Fast, unopinionated web framework
- **Puppeteer 24.26.1** - Headless Chrome crawler
- **Cheerio 1.1.2** - Fast, flexible HTML parser
- **CORS 2.8.5** - Cross-Origin Resource Sharing
- **dotenv 17.2.3** - Environment configuration
- **Nodemon 3.1.10** - Auto-restart development server

## üìÅ C·∫•u tr√∫c th∆∞ m·ª•c

```
backend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ index.js                    # Express server entry point
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analyze.js              # API routes definition
‚îÇ   ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analyzeController.js    # Request handlers
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyzerService.js      # Business logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ crawlerService.js       # Puppeteer crawler
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ parsers.js              # Cheerio HTML parsers
‚îÇ       ‚îú‚îÄ‚îÄ validators.js           # URL validation
‚îÇ       ‚îî‚îÄ‚îÄ scoring.js              # SEO score calculation
‚îú‚îÄ‚îÄ .env                            # Environment variables
‚îú‚îÄ‚îÄ .gitignore                      # Git ignore rules
‚îú‚îÄ‚îÄ package.json                    # Dependencies and scripts
‚îî‚îÄ‚îÄ README.md                       # This file
```

## üõ†Ô∏è C√†i ƒë·∫∑t

### Y√™u c·∫ßu h·ªá th·ªëng

- Node.js >= 20.19.0 ho·∫∑c >= 22.12.0
- npm ho·∫∑c yarn
- ~200MB disk space (Chromium binary)

### C√°c b∆∞·ªõc c√†i ƒë·∫∑t

1. **C√†i ƒë·∫∑t dependencies:**

```bash
npm install
```

Puppeteer s·∫Ω t·ª± ƒë·ªông download Chromium (~170MB) l·∫ßn ƒë·∫ßu.

2. **C·∫•u h√¨nh m√¥i tr∆∞·ªùng:**

File `.env` ƒë√£ ƒë∆∞·ª£c t·∫°o s·∫µn:

```properties
PORT=3000
NODE_ENV=development
CORS_ORIGIN=http://localhost:5173
PUPPETEER_TIMEOUT=30000
PUPPETEER_HEADLESS=true
```

## üèÉ Ch·∫°y ·ª©ng d·ª•ng

### Development Mode (v·ªõi Nodemon)

```bash
npm run dev
```

Server s·∫Ω ch·∫°y t·∫°i: http://localhost:3000

Nodemon s·∫Ω t·ª± ƒë·ªông restart khi c√≥ thay ƒë·ªïi code.

### Production Mode

```bash
npm start
```

## üì° API Endpoints

### POST /api/analyze

Ph√¢n t√≠ch SEO cho m·ªôt URL.

**Request:**

```json
{
  "url": "https://example.com/article"
}
```

**Response (Success):**

```json
{
  "success": true,
  "data": {
    "url": "https://example.com/article",
    "timestamp": "2025-10-29T10:30:00.000Z",
    "score": 85,
    "checks": {
      "hasJsonLd": true,
      "hasAuthor": true,
      "hasMetaDescription": true,
      "metaDescriptionLength": 155,
      "h2Count": 5,
      "hasOgTags": true,
      "hasCanonical": true
    },
    "details": {
      "jsonLd": {
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": "...",
        "author": {...}
      },
      "metaDescription": "Article description...",
      "headings": {
        "h1": 1,
        "h2": 5,
        "h3": 8
      },
      "ogTags": {
        "og:title": "...",
        "og:description": "...",
        "og:image": "..."
      },
      "canonical": "https://example.com/article"
    }
  }
}
```

**Response (Error):**

```json
{
  "success": false,
  "error": {
    "code": "INVALID_URL",
    "message": "Invalid URL format"
  }
}
```

**Error Codes:**

- `INVALID_URL` - URL kh√¥ng h·ª£p l·ªá
- `FETCH_ERROR` - Kh√¥ng th·ªÉ fetch URL (timeout, network error)
- `PARSE_ERROR` - L·ªói khi parse HTML

## üß™ Testing

### Test v·ªõi PowerShell

```powershell
# Test basic endpoint
$body = @{
    url = "https://vnexpress.net"
} | ConvertTo-Json

Invoke-RestMethod -Uri "http://localhost:3000/api/analyze" `
    -Method Post `
    -Body $body `
    -ContentType "application/json"
```

### Test v·ªõi curl

```bash
curl -X POST http://localhost:3000/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"url":"https://vnexpress.net"}'
```

### Test URLs (Vietnamese News Sites)

1. **VNExpress:** `https://vnexpress.net`
2. **D√¢n Tr√≠:** `https://dantri.com.vn`
3. **ZingNews:** `https://zingnews.vn`
4. **Tu·ªïi Tr·∫ª:** `https://tuoitre.vn`
5. **Thanh Ni√™n:** `https://thanhnien.vn`

### International Sites

1. **Medium:** `https://medium.com`
2. **Dev.to:** `https://dev.to`
3. **TechCrunch:** `https://techcrunch.com`

**Note:** M·ªói request m·∫•t **10-30 gi√¢y** do Puppeteer c·∫ßn th·ªùi gian ƒë·ªÉ:
- Launch headless browser
- Navigate to URL
- Wait for page load
- Extract HTML content

## üîß Scoring Algorithm

ƒêi·ªÉm SEO ƒë∆∞·ª£c t√≠nh theo c√¥ng th·ª©c weighted scoring:

| Ti√™u ch√≠ | ƒêi·ªÉm t·ªëi ƒëa | M√¥ t·∫£ |
|----------|-------------|-------|
| JSON-LD Schema | 20 | C√≥ structured data |
| Author trong JSON-LD | 15 | C√≥ th√¥ng tin t√°c gi·∫£ |
| Meta Description | 20 | C√≥ v√† ƒë·ªô d√†i 50-160 k√Ω t·ª± |
| H2 Headings | 15 | S·ªë l∆∞·ª£ng H2 trong kho·∫£ng 3-8 |
| Open Graph Tags | 15 | C√≥ OG tags (title, description, image) |
| Canonical URL | 15 | C√≥ canonical link |

**T·ªïng ƒëi·ªÉm:** 0-100%

## üîç Services & Utils

### CrawlerService (Puppeteer)

```javascript
// Launch headless Chrome
const browser = await puppeteer.launch({ headless: true })
const page = await browser.newPage()

// Navigate with 30s timeout
await page.goto(url, { 
  waitUntil: 'networkidle0',
  timeout: 30000 
})

// Extract HTML
const html = await page.content()
```

### Parsers (Cheerio)

```javascript
// Extract JSON-LD
const jsonLd = extractJsonLd($)

// Extract meta description
const metaDescription = extractMetaDescription($)

// Count headings (H1, H2, H3)
const headings = countHeadings($)

// Extract Open Graph tags
const ogTags = extractOgTags($)

// Extract canonical URL
const canonical = extractCanonical($)
```

### Validators

```javascript
// Validate URL format
const isValid = isValidUrl(url)
// Returns: true/false
```

### Scoring

```javascript
// Calculate SEO score (0-100)
const score = calculateScore(checks)
```

## üêõ Troubleshooting

### Port 3000 ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng

```bash
# Ki·ªÉm tra process ƒëang d√πng port 3000
Get-NetTCPConnection -LocalPort 3000 | Select-Object OwningProcess

# D·ª´ng process
Stop-Process -Id <ProcessId> -Force
```

Ho·∫∑c thay ƒë·ªïi port trong `.env`:
```properties
PORT=3001
```

### Puppeteer l·ªói "Failed to launch chrome"

C√†i ƒë·∫∑t l·∫°i Chromium:

```bash
Remove-Item -Recurse -Force node_modules
Remove-Item package-lock.json
npm install
```

### CORS errors

ƒê·∫£m b·∫£o `CORS_ORIGIN` trong `.env` kh·ªõp v·ªõi frontend URL:

```properties
CORS_ORIGIN=http://localhost:5173
```

### Timeout errors

TƒÉng timeout trong `.env`:

```properties
PUPPETEER_TIMEOUT=60000
```

## üöÄ Production Deployment

### Build & Deploy

1. Set environment to production:

```bash
NODE_ENV=production
PUPPETEER_HEADLESS=true
```

2. Install production dependencies only:

```bash
npm install --production
```

3. Start server:

```bash
npm start
```

### Recommended Hosting

- **Railway** - Easy deployment, automatic HTTPS
- **Render** - Free tier v·ªõi auto-sleep
- **Heroku** - Classic PaaS (buildpack needed for Puppeteer)
- **DigitalOcean** - VPS v·ªõi full control

### Docker Support (Optional)

Create `Dockerfile`:

```dockerfile
FROM node:20-slim

# Install Chromium dependencies
RUN apt-get update && apt-get install -y \
    chromium \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY package*.json ./
RUN npm install --production
COPY . .

ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
ENV PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium

EXPOSE 3000
CMD ["npm", "start"]
```

## üìù Development Guidelines

### Error Handling

T·∫•t c·∫£ errors ƒë∆∞·ª£c catch v√† return format nh·∫•t qu√°n:

```javascript
try {
  // Logic
} catch (error) {
  return res.status(500).json({
    success: false,
    error: {
      code: 'ERROR_CODE',
      message: error.message
    }
  })
}
```

### Logging

Console logs cho debugging:

```javascript
console.log('üöÄ Server running on http://localhost:3000')
console.log('üìù Analyzing URL:', url)
console.log('‚úÖ Analysis complete')
```

## üìÑ License

ISC License - D·ª± √°n h·ªçc t·∫≠p IS207.Q13

## üë• Contributors

Nh√≥m sinh vi√™n UIT - IS207.Q13
